{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smjo/anaconda3/envs/xai_timeseries/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f85545fe770>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import pandas as pd\n",
    "import argparse                 \n",
    "import sklearn \n",
    "import numpy as np \n",
    "import logging \n",
    "import sklearn.metrics as metrics \n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt                                  \n",
    "from argparse import ArgumentParser\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset, Dataset, random_split\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import os \n",
    "import copy\n",
    "import warnings\n",
    "from dataload import makedata\n",
    "from classifier import ClassifierTrainer\n",
    "from models import VQ_Classifier\n",
    "import itertools\n",
    "from data import load_data\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "torch.set_num_threads(32) \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'flat'\n",
    "classification_model = '/home/hschung/xai/xai_timeseries/classification_models/flat_conv_nonoverlap_128_4/model_290.pt'\n",
    "vqvae_model = \"/home/hschung/xai/xai_timeseries/vqvae_models/flat_vqvae_nonoverlap_16_4/model_300.pt\"\n",
    "model_type = 'cnn'\n",
    "num_quantizer = 4\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task is classification\n",
      "dataset is flat\n",
      "X shape:torch.Size([2000, 192]), y shape:torch.Size([2000, 2])\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5'\n",
    "len_position=12\n",
    "ds = load_data(dataset, task = 'classification')\n",
    "\n",
    "train_size = int(0.9 * len(ds))\n",
    "val_size = int(0.1 * len(ds))\n",
    "test_size = len(ds) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(ds, [train_size, val_size, test_size])\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIND codebook combination ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_dict=defaultdict(set)         #position:코드북 조합(len=num_+quantizers)\n",
    "\n",
    "conv_net = VQ_Classifier(\n",
    "    num_classes = 2,\n",
    "    vqvae_model = vqvae_model,\n",
    "    positions =0,\n",
    "    mask = 0,\n",
    "    auc_classification = False,\n",
    "    model_type = model_type,\n",
    "    len_position=len_position\n",
    ").to(device)\n",
    "\n",
    "a = torch.load(classification_model)\n",
    "conv_net.load_state_dict(a['model_state_dict'])\n",
    "\n",
    "for param in conv_net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "conv_net.eval()\n",
    "\n",
    "prev_samples_0=[]\n",
    "prev_samples_1=[]\n",
    "with torch.no_grad():    \n",
    "    score=0\n",
    "    for i,(data, labels) in enumerate(test_loader):\n",
    "        data = data.unsqueeze(1).float()\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        labels = torch.argmax(labels, dim=1)\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        output, codebook_tokens, recon, input= conv_net(data)\n",
    "        if labels==0:\n",
    "            prev_samples_0.append(codebook_tokens)\n",
    "        else:\n",
    "            prev_samples_1.append(codebook_tokens)\n",
    "        #첫번째 코드북에 따라 유니크한 조합이 생성되는지 확인\n",
    "        for idx in range(len_position):\n",
    "            codebook_dict[idx].add(codebook_tokens[0,idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conbt = {key:len(val) for key, val in codebook_dict.items()}\n",
    "conbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 28,  99,  36,  12,  12,  26,  25,  69],\n",
       "         [ 77,  72,  69,  13,  51,  69,  62,  60],\n",
       "         [ 54,  19,  13,  97,  54,  45,  94,  59],\n",
       "         [ 28, 126, 126,  25,  73,  71,  33,  33],\n",
       "         [ 42,  37, 115,  91,  16,  72,  79,  41],\n",
       "         [ 42,  37, 115,  91,  16,  72,  79,  41],\n",
       "         [ 42,  37, 115,  91,  16,  72,  79,  41],\n",
       "         [ 42,  37, 115,  91,  16,  72,  79,  41],\n",
       "         [ 42,  37, 115,  91,  16,  72,  79,  41],\n",
       "         [ 42,  37, 115,  91,  16,  72,  79,  41],\n",
       "         [ 42,  37, 115,  91,  16,  72,  79,  41],\n",
       "         [ 42,  37, 115,  91,  16,  72,  79,  41]]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codebook_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturb each position with codebook_dict and generate new samples###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_perturb(pos, prev_sample, codebook_dict):\n",
    "    result = []\n",
    "    for voluteer in codebook_dict[pos]:\n",
    "        tmp = prev_sample.clone().detach()\n",
    "        print(voluteer.shape)\n",
    "        print(tmp.shape)\n",
    "        tmp[0,pos,:] = voluteer\n",
    "        result.append(tmp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 8])\n",
      "torch.Size([1, 12, 8])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.cuda.LongTensor{[12, 8]}, size=[8]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m new_samples_0\u001b[39m=\u001b[39mdefaultdict(\u001b[39mlist\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m pos \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(len_position):\n\u001b[0;32m----> 5\u001b[0m     tmp \u001b[39m=\u001b[39m greedy_perturb(pos,sample, codebook_dict)\n\u001b[1;32m      6\u001b[0m     new_samples_0[sample]\u001b[39m.\u001b[39mappend(tmp)\n\u001b[1;32m      7\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[68], line 7\u001b[0m, in \u001b[0;36mgreedy_perturb\u001b[0;34m(pos, prev_sample, codebook_dict)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(voluteer\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(tmp\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 7\u001b[0m     tmp[\u001b[39m0\u001b[39;49m,pos,:] \u001b[39m=\u001b[39m voluteer\n\u001b[1;32m      8\u001b[0m     result\u001b[39m.\u001b[39mappend(tmp)\n\u001b[1;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.cuda.LongTensor{[12, 8]}, size=[8]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, sample in enumerate(prev_samples_0):\n",
    "    new_samples_0=defaultdict(list)\n",
    "    \n",
    "    for pos in range(len_position):\n",
    "        tmp = greedy_perturb(pos,sample, codebook_dict)\n",
    "        new_samples_0[sample].append(tmp)\n",
    "    break\n",
    "'''\n",
    "    \n",
    "for idx, sample in enumerate(prev_samples_1):\n",
    "    new_samples_1=defaultdict(list)\n",
    "    new_samples_1[sample].append(greedy_perturb(sample))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(codebook_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai_timeseries",
   "language": "python",
   "name": "xai_timeseries"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
