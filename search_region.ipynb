{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7facfa2733f0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import pandas as pd\n",
    "import argparse                 \n",
    "import sklearn \n",
    "import numpy as np \n",
    "import logging \n",
    "import sklearn.metrics as metrics \n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt                                  \n",
    "from argparse import ArgumentParser\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset, Dataset, random_split\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import os \n",
    "import copy\n",
    "import warnings\n",
    "from dataload import makedata\n",
    "from classifier import ClassifierTrainer\n",
    "from models import VQ_Classifier\n",
    "import itertools\n",
    "from data import load_data\n",
    "torch.manual_seed(911) \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task is classification\n",
      "dataset is mitbih\n",
      "X shape:torch.Size([8039, 192]), y shape:torch.Size([8039, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smjo/xai_timeseries/data.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  n_set = torch.tensor(torch.load('./mit_bih_dataset/n_data.pt'))\n",
      "/home/smjo/xai_timeseries/data.py:123: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s_set = torch.tensor(torch.load('./mit_bih_dataset/s_data.pt'))\n",
      "/home/smjo/xai_timeseries/data.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  v_set = torch.tensor(torch.load('./mit_bih_dataset/v_data.pt'))\n",
      "/home/smjo/xai_timeseries/data.py:125: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  f_set = torch.tensor(torch.load('./mit_bih_dataset/f_data.pt'))\n",
      "/home/smjo/xai_timeseries/data.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  q_set = torch.tensor(torch.load('./mit_bih_dataset/q_data.pt'))\n",
      "/home/smjo/xai_timeseries/data.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  n_label = torch.tensor(torch.load('./mit_bih_dataset/n_labels.pt'))\n",
      "/home/smjo/xai_timeseries/data.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s_label = torch.tensor(torch.load('./mit_bih_dataset/s_labels.pt'))\n",
      "/home/smjo/xai_timeseries/data.py:131: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  v_label = torch.tensor(torch.load('./mit_bih_dataset/v_labels.pt'))-2\n",
      "/home/smjo/xai_timeseries/data.py:132: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  f_label = torch.tensor(torch.load('./mit_bih_dataset/f_labels.pt'))-2\n",
      "/home/smjo/xai_timeseries/data.py:133: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  q_label = torch.tensor(torch.load('./mit_bih_dataset/q_labels.pt'))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "len_position=12\n",
    "dataset = 'mitbih'\n",
    "classifier = 'cnn'\n",
    "classification_model = \"/home/smjo/xai_timeseries/vqvae/saved_models/classification/mitbih/8/cnn.pt\"\n",
    "vqvae_model = \"/home/smjo/xai_timeseries/vqvae/saved_models/hard_mitbih/8/model_290.pt\"\n",
    "ds = load_data(dataset, task = 'classification')\n",
    "\n",
    "\n",
    "\n",
    "test_size = 80\n",
    "train_size = len(ds)-test_size\n",
    "train_dataset,test_dataset = random_split(ds, [train_size,test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "#Find masking token\n",
    "end_tokens={}\n",
    "\n",
    "net = VQ_Classifier(\n",
    "    num_classes = 2,\n",
    "    vqvae_model = vqvae_model,\n",
    "    positions =0,\n",
    "    mask = 0,\n",
    "    auc_classification = False,\n",
    "    model_type = classifier,\n",
    "    len_position = len_position\n",
    ").to(device)\n",
    "\n",
    "a = torch.load(classification_model)\n",
    "net.load_state_dict(a['model_state_dict'])\n",
    "\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(codebook_tokens,pos, item, quant):\n",
    "    if codebook_tokens[0][pos][quant] == item[0][quant]:\n",
    "        return 'exist'\n",
    "    else:\n",
    "        return 'not_exist'\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### region : 몇번째 quantizer 까지 볼껀지 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_code_class0 = {pos:list() for pos in range(len_position)}\n",
    "count_code_class1 = {pos:list() for pos in range(len_position)}\n",
    "class0, class1=0,0\n",
    "region=3 \n",
    "with torch.no_grad():    \n",
    "    for _, (data, labels) in enumerate(test_loader):\n",
    "        data = data.unsqueeze(1).float()\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        labels = torch.argmax(labels, dim=1)\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        output, codebook_tokens, recon, input= net(data)\n",
    "        codebook_tokens = codebook_tokens.cpu().detach().numpy()\n",
    "        if labels==0:\n",
    "            class0+=1\n",
    "            for pos in range(len_position):\n",
    "                \n",
    "                state = 'not_exist'\n",
    "                for item_idx,item in enumerate(count_code_class0[pos]):\n",
    "                    for quant in range(region):\n",
    "                        state = compare(codebook_tokens,pos, item,quant)\n",
    "                        if state =='not_exist':\n",
    "                            break\n",
    "                    if state =='exist':\n",
    "                        count_code_class0[pos][item_idx][1] +=1\n",
    "                        break\n",
    "                if state =='not_exist':\n",
    "                    count_code_class0[pos].append([tuple(codebook_tokens[0][pos][:region]),1])\n",
    "                    continue\n",
    "\n",
    "        else:\n",
    "            class1+=1\n",
    "            for pos in range(len_position):\n",
    "                state = 'not_exist'\n",
    "                for item_idx,item in enumerate(count_code_class1[pos]):\n",
    "                    for quant in range(region):\n",
    "                        state = compare(codebook_tokens,pos, item,quant)\n",
    "                        if state =='not_exist':\n",
    "                            break\n",
    "                    if state =='exist':\n",
    "                        count_code_class1[pos][item_idx][1] +=1\n",
    "                        break\n",
    "                if state =='not_exist':\n",
    "                    count_code_class1[pos].append([tuple(codebook_tokens[0][pos][:region]),1])\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_overlapping = {pos:0 for pos in range(len_position)}\n",
    "for pos in range(len_position):\n",
    "    for i,code_i in enumerate(count_code_class0[pos]):\n",
    "        for k, code_k in enumerate(count_code_class1[pos]):\n",
    "            if code_i[0] == code_k[0]:\n",
    "                #print(f\"position:{pos}, codebook:{code_k[0]}, class0:{code_k[1]}, class1: {code_i[1]}\")\n",
    "                count_overlapping[pos]+=min(code_i[1], code_k[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class 간 position 별로 겹치는 sample 개수, class0 sample 개수, class 1 sample 개수 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0, 1: 1, 2: 0, 3: 0, 4: 0, 5: 1, 6: 2, 7: 4, 8: 6, 9: 7, 10: 7, 11: 7},\n",
       " 67,\n",
       " 13)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_overlapping , class0, class1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai_timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "821750203aafa3e6725a7c11719996c58f17f2ae5c4a806c3d30396549224564"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
