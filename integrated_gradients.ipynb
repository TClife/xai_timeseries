{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgustmd0121\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hschung/xai_workshop/timeseries/wandb/run-20230609_001818-3q39x0v3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gustmd0121/timeseries/runs/3q39x0v3\" target=\"_blank\">confused-eon-340</a></strong> to <a href=\"https://wandb.ai/gustmd0121/timeseries\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "from dalle_vqvae.classification_unofficial import VQVAE_Conv\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd \n",
    "\n",
    "torch.set_num_threads(32)\n",
    "torch.manual_seed(911) \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"peak\"\n",
    "vqvae_model = \"/home/hschung/saved_models/timeseries/peak2/model_2990.pt\"\n",
    "model_type = \"cnn_transformer\"\n",
    "classification_model = \"/home/hschung/saved_models/timeseries/peak_clas_cnn_transf/classification_80.pt\"\n",
    "\n",
    "#ECG Dataset\n",
    "net = VQVAE_Conv(\n",
    "    n_emb = 64,\n",
    "    num_classes = 2,\n",
    "    vqvae_model = vqvae_model,\n",
    "    positions = 0,\n",
    "    mask = 0,\n",
    "    auc_classification = False,\n",
    "    model_type = model_type\n",
    ")\n",
    "  \n",
    "#Classification Model for LIME training\n",
    "net.load_state_dict(torch.load(classification_model)[\"model_state_dict\"])\n",
    "\n",
    "#params\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False \n",
    "\n",
    "if dataset == \"flat\":\n",
    "    class0_pth = '/home/smjo/xai/timeseries_xai/data/made_data/amplitude_class0.csv'\n",
    "    class1_pth = '/home/smjo/xai/timeseries_xai/data/made_data/amplitude_class1.csv'\n",
    "    class0_data = torch.tensor(pd.read_csv(class0_pth,skiprows=0).values)\n",
    "    class1_data = torch.tensor(pd.read_csv(class1_pth,skiprows=0).values)\n",
    "    class0_label = torch.zeros(len(class0_data))\n",
    "    class1_label = torch.ones(len(class1_data))\n",
    "\n",
    "    data = torch.cat((class0_data,class1_data), dim=0)\n",
    "    labels = torch.cat((class0_label, class1_label), dim=0)\n",
    "\n",
    "elif dataset == \"peak\":\n",
    "    class0_pth = '/home/smjo/xai/timeseries_xai/data/made_data/class0.csv'\n",
    "    class1_pth = '/home/smjo/xai/timeseries_xai/data/made_data/class1.csv'\n",
    "    class0_data = torch.tensor(pd.read_csv(class0_pth,skiprows=0).values)\n",
    "    class1_data = torch.tensor(pd.read_csv(class1_pth,skiprows=0).values)\n",
    "    class0_label = torch.zeros(len(class0_data))\n",
    "    class1_label = torch.ones(len(class1_data))\n",
    "    \n",
    "    data = torch.cat((class0_data,class1_data), dim=0)\n",
    "    labels = torch.cat((class0_label, class1_label), dim=0)    \n",
    "\n",
    "elif dataset == \"hard_mitbih\":\n",
    "    n_set = torch.tensor(torch.load('/home/hschung/xai_workshop/timeseries/mit_bih_dataset/n_data.pt'))\n",
    "    n_label = torch.tensor(torch.load('/home/hschung/xai_workshop/timeseries/mit_bih_dataset/n_labels.pt'))\n",
    "    s_set = torch.tensor(torch.load('/home/hschung/xai_workshop/timeseries/mit_bih_dataset/s_data.pt'))\n",
    "    s_label = torch.tensor(torch.load('/home/hschung/xai_workshop/timeseries/mit_bih_dataset/s_labels.pt'))\n",
    "    v_set = torch.tensor(torch.load('/home/hschung/xai_workshop/timeseries/mit_bih_dataset/v_data.pt'))[:400]\n",
    "    v_label = torch.tensor(torch.load('/home/hschung/xai_workshop/timeseries/mit_bih_dataset/v_labels.pt'))[:400]-2\n",
    "    f_set = torch.tensor(torch.load('/home/hschung/xai_workshop/timeseries/mit_bih_dataset/f_data.pt'))[:400]\n",
    "    f_label = torch.tensor(torch.load('/home/hschung/xai_workshop/timeseries/mit_bih_dataset/f_labels.pt'))[:400]-2\n",
    "    q_set = torch.tensor(torch.load('/home/hschung/xai_workshop/timeseries/mit_bih_dataset/q_data.pt'))\n",
    "    q_label = torch.tensor(torch.load('/home/hschung/xai_workshop/timeseries/mit_bih_dataset/q_labels.pt'))-3\n",
    "\n",
    "    ecg_train = torch.cat((v_set, f_set), dim=0)\n",
    "    labels = torch.cat((v_label, f_label), dim=0)\n",
    "\n",
    "    data = ecg_train\n",
    "    \n",
    "    print(f\"X shape:{data.shape}, label shape:{labels.shape}\")  \n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "ds = ECGDataset(data, labels)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_size = int(0.8 * len(ds))\n",
    "val_size = int(0.1 * len(ds))\n",
    "test_size = len(ds) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(ds, [train_size, val_size, test_size])\n",
    "training_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=True)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Input and Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([142, 13])\n",
      "torch.Size([142, 13, 64])\n",
      "torch.Size([142, 2])\n",
      "torch.Size([142, 1, 208])\n",
      "torch.Size([142])\n",
      "torch.Size([142, 1, 208])\n"
     ]
    }
   ],
   "source": [
    "# test dataset information \n",
    "ig_misc = torch.load(\"/home/hschung/xai_workshop/timeseries/integrated_gradients/peak_dataset_IG_cnn_transformer.pt\")\n",
    "codebook_tokens = ig_misc[\"codebook_tokens\"]\n",
    "input = ig_misc[\"input\"]\n",
    "output = ig_misc[\"output\"]\n",
    "recon = ig_misc[\"recon\"]\n",
    "labels = ig_misc[\"labels\"]\n",
    "data = ig_misc[\"data\"]\n",
    "\n",
    "labels = labels.squeeze(0)\n",
    "\n",
    "print(codebook_tokens.shape)\n",
    "print(input.shape)\n",
    "print(output.shape)\n",
    "print(recon.shape)\n",
    "print(labels.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)\n",
    "model_input = net.embedding #embedding layer output (as model_input)\n",
    "model_input, codebook_tokens = model_input.to(device), codebook_tokens.to(device)\n",
    "embedded = model_input(codebook_tokens)\n",
    "embedded.shape\n",
    "\n",
    "# Define model output\n",
    "def model_output(inputs):\n",
    "  return net.ig(inputs)[0][:,0] #[1,4] -> [4] get the fc-layer output from embedded input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Integrated Gradients Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function model_output at 0x7ff644696dc0>\n",
      "Embedding(64, 64)\n"
     ]
    }
   ],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "lig = LayerIntegratedGradients(model_output, model_input)\n",
    "print(model_output)\n",
    "print(model_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide testset samples into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_codebook_tokens = []\n",
    "for i in range(len(labels)):\n",
    "    total_codebook_tokens.append(codebook_tokens[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_tokens= torch.stack(total_codebook_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Original and Baseline Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original input: tensor([[63, 63, 63,  ..., 28,  7, 63],\n",
      "        [53, 53, 53,  ..., 45, 10, 53],\n",
      "        [59, 59, 59,  ..., 61, 10, 59],\n",
      "        ...,\n",
      "        [41, 18, 15,  ...,  0,  0,  0],\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "        [19, 19, 19,  ..., 34, 37, 19]], device='cuda:0')\n",
      "baseline input: tensor([[63, 63, 63,  ..., 63, 63, 63],\n",
      "        [63, 63, 63,  ..., 63, 63, 63],\n",
      "        [63, 63, 63,  ..., 63, 63, 63],\n",
      "        ...,\n",
      "        [63, 63, 63,  ..., 63, 63, 63],\n",
      "        [63, 63, 63,  ..., 63, 63, 63],\n",
      "        [63, 63, 63,  ..., 63, 63, 63]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#select class\n",
    "baseline_tokens = torch.full(codebook_tokens.shape, 63, device=device)\n",
    "codebook_tokens = codebook_tokens.to(device)\n",
    "print(f'original input: {codebook_tokens}')\n",
    "print(f'baseline input: {baseline_tokens}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([142, 13])\n",
      "torch.Size([142, 13])\n",
      "tensor([[[-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 1.7465e-03, -1.2826e-03, -7.9215e-05,  ...,  2.8288e-03,\n",
      "          -3.8508e-03,  1.6124e-04],\n",
      "         [ 9.1765e-04,  1.5992e-03,  1.0286e-03,  ..., -1.0455e-03,\n",
      "           3.1748e-04, -1.3439e-02],\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[ 3.3051e-04,  2.3044e-04, -1.7836e-04,  ...,  5.3211e-04,\n",
      "           1.9982e-04,  1.9137e-03],\n",
      "         [ 2.1213e-03, -2.6549e-04, -1.9601e-04,  ...,  1.6951e-03,\n",
      "           3.2032e-03,  5.4400e-03],\n",
      "         [ 2.9070e-03, -1.2844e-03, -3.3254e-04,  ...,  1.0946e-03,\n",
      "          -1.4643e-03,  4.9250e-03],\n",
      "         ...,\n",
      "         [ 8.8066e-03,  6.1908e-03, -1.8651e-04,  ...,  9.5220e-04,\n",
      "          -9.5723e-03,  1.4217e-03],\n",
      "         [-1.1325e-03, -2.7482e-03,  1.0426e-03,  ...,  2.1987e-03,\n",
      "           2.9494e-04,  1.0967e-03],\n",
      "         [ 1.9772e-03,  5.9916e-04,  4.9478e-05,  ..., -6.5463e-04,\n",
      "           2.7662e-03, -1.3879e-03]],\n",
      "\n",
      "        [[-2.1206e-03,  2.4925e-04, -8.3934e-04,  ..., -7.7877e-04,\n",
      "           3.5903e-04, -2.3693e-03],\n",
      "         [-1.2328e-03,  5.2728e-05, -1.0834e-04,  ..., -2.8707e-03,\n",
      "           5.0966e-04, -3.1921e-03],\n",
      "         [ 1.8578e-04,  6.9480e-04,  5.3350e-04,  ..., -2.4550e-03,\n",
      "          -5.6099e-04, -2.0886e-04],\n",
      "         ...,\n",
      "         [ 6.5915e-04,  1.9480e-03, -2.6209e-03,  ...,  1.1304e-03,\n",
      "          -1.6753e-02, -1.6095e-04],\n",
      "         [ 2.7805e-04, -2.5960e-03,  1.1601e-04,  ...,  1.7647e-03,\n",
      "           5.9928e-04,  1.9328e-03],\n",
      "         [ 8.8660e-04, -3.7455e-04,  1.2706e-04,  ...,  8.4463e-04,\n",
      "           1.5487e-03, -1.2155e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.8533e-03,  1.1936e-04, -3.0384e-04,  ..., -7.2895e-04,\n",
      "          -2.0845e-03, -7.2521e-04],\n",
      "         [-1.1126e-03, -4.5810e-03,  1.6415e-03,  ...,  5.0523e-04,\n",
      "          -2.6341e-03,  1.3055e-03],\n",
      "         [-3.4791e-04,  2.1667e-03,  2.2933e-04,  ..., -1.2390e-03,\n",
      "          -1.0506e-04, -9.1854e-03],\n",
      "         ...,\n",
      "         [ 1.1155e-02,  3.8170e-03, -3.5172e-04,  ..., -1.6009e-03,\n",
      "          -7.8495e-04, -6.9316e-05],\n",
      "         [ 8.3460e-03,  2.2266e-03,  6.7375e-05,  ...,  3.8883e-04,\n",
      "           9.6865e-05, -7.8872e-04],\n",
      "         [ 6.4799e-03,  6.0603e-04, -2.7368e-04,  ...,  1.6677e-03,\n",
      "          -5.5783e-04,  3.7073e-03]],\n",
      "\n",
      "        [[-1.3553e-03,  9.3545e-04, -2.6910e-04,  ...,  9.7086e-05,\n",
      "          -3.7371e-05,  8.0687e-05],\n",
      "         [ 1.0278e-03, -7.8443e-04, -2.3476e-04,  ...,  3.5542e-04,\n",
      "           1.0484e-03,  1.6053e-04],\n",
      "         [ 2.2079e-03, -6.6107e-04, -1.7085e-04,  ..., -1.1578e-04,\n",
      "          -6.1765e-04, -8.7177e-04],\n",
      "         ...,\n",
      "         [ 3.2721e-03,  2.1686e-03, -3.9453e-04,  ..., -1.7404e-04,\n",
      "          -7.8318e-04, -4.2085e-04],\n",
      "         [ 1.3971e-03,  1.8905e-03, -7.3437e-05,  ..., -3.8416e-04,\n",
      "           6.9119e-04,  8.6100e-05],\n",
      "         [-7.3560e-04, -1.5716e-03, -5.6524e-05,  ..., -2.4747e-04,\n",
      "           1.4747e-04,  1.0432e-03]],\n",
      "\n",
      "        [[ 3.1759e-03, -2.2760e-03, -5.0140e-05,  ...,  2.2740e-03,\n",
      "          -9.7048e-04,  6.1456e-04],\n",
      "         [-5.2947e-03, -3.7345e-03,  4.8011e-05,  ..., -6.8813e-03,\n",
      "           4.4109e-04, -4.1314e-03],\n",
      "         [-1.9916e-03, -4.0513e-03,  2.4742e-04,  ..., -1.4958e-02,\n",
      "          -3.8250e-04, -2.4206e-03],\n",
      "         ...,\n",
      "         [-1.4577e-03, -2.6479e-03,  4.0919e-03,  ..., -1.4657e-04,\n",
      "           5.7949e-03,  2.8928e-03],\n",
      "         [ 1.3735e-04, -1.0572e-03,  4.6530e-05,  ...,  3.4037e-03,\n",
      "          -5.5404e-03,  9.0948e-03],\n",
      "         [-2.2571e-03, -1.3519e-03, -1.2430e-05,  ...,  1.0931e-03,\n",
      "           1.8836e-04, -1.7845e-03]]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(codebook_tokens.shape)\n",
    "print(baseline_tokens.shape)\n",
    "baseline_tokens = baseline_tokens.to(device)\n",
    "attributions, delta = lig.attribute(inputs = codebook_tokens, baselines = baseline_tokens, return_convergence_delta=True)\n",
    "\n",
    "print(attributions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Attribution for Each Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([142, 13])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0303, -0.0167,  0.0000],\n",
      "        [ 0.0116,  0.0194,  0.0046,  ..., -0.0285,  0.0213,  0.0077],\n",
      "        [ 0.0107, -0.0007, -0.0027,  ..., -0.0046, -0.0071,  0.0087],\n",
      "        ...,\n",
      "        [ 0.0104,  0.0003, -0.0574,  ...,  0.0189,  0.0187,  0.0141],\n",
      "        [ 0.0090, -0.0080, -0.0073,  ...,  0.0040,  0.0035,  0.0035],\n",
      "        [ 0.0118,  0.0164,  0.0165,  ..., -0.0376, -0.0247,  0.0064]],\n",
      "       device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def summarize_attributions(attributions):\n",
    "\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    \n",
    "    return attributions\n",
    "\n",
    "attributions_sum = summarize_attributions(attributions) #[1, 6, 768] -> [6]\n",
    "print(attributions_sum.size())\n",
    "print(attributions_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9, 10],\n",
       "        [ 7,  6],\n",
       "        [ 0, 12],\n",
       "        [ 6,  4],\n",
       "        [ 8,  0],\n",
       "        [ 7,  8],\n",
       "        [10,  9],\n",
       "        [ 2,  6],\n",
       "        [ 5,  6],\n",
       "        [ 3,  2],\n",
       "        [ 2,  0],\n",
       "        [ 4,  6],\n",
       "        [12,  8],\n",
       "        [ 3,  8],\n",
       "        [ 9,  7],\n",
       "        [ 4, 12],\n",
       "        [ 8,  9],\n",
       "        [ 1,  0],\n",
       "        [ 6,  0],\n",
       "        [ 6, 11],\n",
       "        [ 0,  7],\n",
       "        [ 3, 11],\n",
       "        [ 8,  9],\n",
       "        [ 7,  1],\n",
       "        [ 5,  2],\n",
       "        [12,  0],\n",
       "        [ 8,  9],\n",
       "        [ 5,  8],\n",
       "        [10,  5],\n",
       "        [10,  6],\n",
       "        [ 9, 10],\n",
       "        [ 1,  0],\n",
       "        [ 7,  2],\n",
       "        [ 5,  4],\n",
       "        [10,  9],\n",
       "        [ 8,  1],\n",
       "        [ 7, 11],\n",
       "        [ 3,  1],\n",
       "        [10,  9],\n",
       "        [10,  6],\n",
       "        [ 8,  9],\n",
       "        [ 8,  9],\n",
       "        [ 3,  6],\n",
       "        [ 5,  1],\n",
       "        [ 5,  8],\n",
       "        [10, 11],\n",
       "        [ 9,  8],\n",
       "        [11,  7],\n",
       "        [ 4,  5],\n",
       "        [ 6,  3],\n",
       "        [ 7,  2],\n",
       "        [11, 12],\n",
       "        [ 6,  5],\n",
       "        [ 4, 10],\n",
       "        [11, 12],\n",
       "        [ 1,  2],\n",
       "        [ 5,  3],\n",
       "        [ 7,  6],\n",
       "        [ 8, 10],\n",
       "        [ 1,  4],\n",
       "        [ 9,  8],\n",
       "        [ 7,  8],\n",
       "        [ 3,  1],\n",
       "        [11,  6],\n",
       "        [ 6,  7],\n",
       "        [ 9,  7],\n",
       "        [ 5,  4],\n",
       "        [ 3,  6],\n",
       "        [ 6,  1],\n",
       "        [ 6,  1],\n",
       "        [ 4,  3],\n",
       "        [11,  6],\n",
       "        [ 7, 10],\n",
       "        [ 8,  0],\n",
       "        [ 6,  2],\n",
       "        [ 3,  7],\n",
       "        [ 6,  9],\n",
       "        [ 5,  9],\n",
       "        [ 5,  6],\n",
       "        [ 1,  4],\n",
       "        [ 6,  2],\n",
       "        [ 4,  6],\n",
       "        [ 4,  1],\n",
       "        [ 4,  2],\n",
       "        [ 7,  6],\n",
       "        [ 4,  0],\n",
       "        [ 8,  7],\n",
       "        [ 6,  7],\n",
       "        [ 2,  6],\n",
       "        [12,  7],\n",
       "        [ 6,  7],\n",
       "        [ 6,  1],\n",
       "        [ 6,  0],\n",
       "        [ 4,  1],\n",
       "        [ 8,  5],\n",
       "        [ 7, 11],\n",
       "        [ 7, 11],\n",
       "        [ 6,  7],\n",
       "        [ 1,  4],\n",
       "        [ 4,  5],\n",
       "        [ 9, 10],\n",
       "        [ 7,  9],\n",
       "        [ 7,  3],\n",
       "        [ 6, 11],\n",
       "        [ 7,  2],\n",
       "        [ 2,  3],\n",
       "        [ 5,  6],\n",
       "        [10,  7],\n",
       "        [ 9,  5],\n",
       "        [ 2,  6],\n",
       "        [ 9,  5],\n",
       "        [ 3,  2],\n",
       "        [ 6,  5],\n",
       "        [ 5,  6],\n",
       "        [ 8,  7],\n",
       "        [ 9,  8],\n",
       "        [ 6, 11],\n",
       "        [11,  8],\n",
       "        [ 3,  9],\n",
       "        [ 1,  2],\n",
       "        [ 6, 10],\n",
       "        [ 5,  6],\n",
       "        [ 6,  0],\n",
       "        [ 2,  4],\n",
       "        [ 7,  8],\n",
       "        [ 7,  1],\n",
       "        [ 5, 10],\n",
       "        [ 6,  7],\n",
       "        [ 5,  4],\n",
       "        [ 4,  5],\n",
       "        [ 8,  5],\n",
       "        [ 8,  0],\n",
       "        [ 9,  6],\n",
       "        [ 8,  5],\n",
       "        [ 8,  5],\n",
       "        [ 5,  8],\n",
       "        [10,  7],\n",
       "        [ 7, 11],\n",
       "        [ 4,  1],\n",
       "        [ 3, 10],\n",
       "        [ 0,  6],\n",
       "        [ 8,  7]], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find top-2 max values and indices\n",
    "top_2_values, top_2_indices = torch.topk(attributions_sum, 2, dim=1) #top-2 values and indices for each sample in testset with class 0\n",
    "top_2_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 43),\n",
       " (7, 34),\n",
       " (8, 29),\n",
       " (5, 28),\n",
       " (9, 23),\n",
       " (4, 21),\n",
       " (1, 19),\n",
       " (10, 18),\n",
       " (2, 17),\n",
       " (3, 16),\n",
       " (11, 15),\n",
       " (0, 14),\n",
       " (12, 7)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final count of important positions\n",
    "from collections import Counter\n",
    "top_indices = [int(item) for sublist in top_2_indices for item in sublist]\n",
    "count = Counter(top_indices).most_common()\n",
    "count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3f03ebb913d1e0285cbef8a22a57c2d5752c709c193e9d81bc5bbabdfe43ca8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('dalle-pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
